{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import concurrent.futures as cf\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I change the type in case of numerical values being str\n",
    "def change_type(df,n=0):\n",
    "    col=df.columns[n]\n",
    "    \n",
    "    if df[col].dtype==\"O\":\n",
    "            try:\n",
    "               df=df.astype({col:\"float64\"})\n",
    "               \n",
    "            except:\n",
    "                df=df.astype({col:\"str\"})\n",
    "                \n",
    "                 \n",
    "            \n",
    "    if n==len(df.columns)-1:\n",
    "        return df\n",
    "    else:\n",
    "        n+=1\n",
    "        return change_type(df,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I create 2 columns and define all time columns \n",
    "def clean_col(df):\n",
    "    \n",
    "    df[\"S_2\"]=df[\"S_2\"].astype('datetime64[ns]')\n",
    "    df[\"Year\"]=df[\"S_2\"].dt.year\n",
    "    df[\"Month\"]=df[\"S_2\"].dt.month\n",
    "\n",
    "    return df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I make  a list of the permutation of each dataframe in the list\n",
    "def reage_list(long,n=0,new_lis1=[],new_lis2=[]):\n",
    "    \n",
    "    new_lis1=list(map(lambda x: [long[n],x],long))\n",
    "\n",
    "    new_lis2=new_lis2+new_lis1\n",
    "\n",
    "    if n==len(long)-1:\n",
    "\n",
    "        new_lis2=list(filter(lambda x:x  if x[0]!=x[1] else None,new_lis2))\n",
    "\n",
    "        return new_lis2\n",
    "\n",
    "    else:\n",
    "\n",
    "        n+=1\n",
    "\n",
    "        return reage_list(long,n,new_lis1,new_lis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I concatonate all the customer_ID into the same data frame and drop that value from the prior dataframe\n",
    "def organise_df(data,inter,n=0):\n",
    "    now=inter[n]\n",
    "    try: \n",
    "    \n",
    "        data[now[0][1]]=pd.concat([data[now[0][1]],data[now[0][0]][data[now[0][0]][\"customer_ID\"]==now[1][0]]])\n",
    "    \n",
    "        data[now[0][0]]=data[now[0][0]].drop(data[now[0][0]][data[now[0][0]][\"customer_ID\"]==now[1][0]].index)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if n==len(inter)-1:\n",
    "        return data\n",
    "    else:\n",
    "        n+=1\n",
    "        return organise_df(data,inter,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_sys(csv):\n",
    "\n",
    "    chunks=pd.read_csv(csv,chunksize=500000)\n",
    "\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        data=list(executor.map(lambda x:x , chunks))\n",
    "\n",
    "    arr=np.arange(len(data)).tolist()\n",
    "    \n",
    "    arr_lis=reage_list(arr)\n",
    "\n",
    "    # here I check using the permutation list the interseption that exist between dataframes in customer_ID \n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        inter=list(executor.map(lambda x:[x, np.intersect1d(data[x[0]][\"customer_ID\"].unique(), (data[x[1]][\"customer_ID\"].unique())).tolist()] ,arr_lis))\n",
    "    \n",
    "\n",
    "    data=organise_df(data,inter)\n",
    "\n",
    "\n",
    "\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        data=list(executor.map(clean_col,data))\n",
    "    \n",
    "\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df=auto_sys(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save each obj in the list to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(lista_df,n=0,lista_link=[]):\n",
    "    \n",
    "    link=\"train_num\"+str(n)+\".csv\"\n",
    "\n",
    "    df=lista_df[n]\n",
    "    \n",
    "    df.to_csv(link)\n",
    "\n",
    "    lista_link.append(link)\n",
    "    \n",
    "    if n==len(lista_df)-1:\n",
    "        \n",
    "        return lista_link\n",
    "\n",
    "    else:\n",
    "\n",
    "        n+=1\n",
    "\n",
    "        return save_csv(lista_df,n,lista_link)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_link=save_csv(lista_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_num0.csv',\n",
       " 'train_num1.csv',\n",
       " 'train_num2.csv',\n",
       " 'train_num3.csv',\n",
       " 'train_num4.csv',\n",
       " 'train_num5.csv',\n",
       " 'train_num6.csv',\n",
       " 'train_num7.csv',\n",
       " 'train_num8.csv',\n",
       " 'train_num9.csv',\n",
       " 'train_num10.csv',\n",
       " 'train_num11.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lista_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I map out all the different month data that exists per Dataframe and had that to a dicionary where the key is the number of months\n",
    "def map_data(data,gr_data,num_data,n=0,dic={}):\n",
    "\n",
    "    \n",
    "\n",
    "    array_ID=gr_data[gr_data[\"S_2\"]==num_data[n]][\"customer_ID\"].unique()\n",
    "\n",
    "    new_frame=data[data[\"customer_ID\"].isin(array_ID)]\n",
    "\n",
    "    dic.update({num_data[n]:new_frame})\n",
    "\n",
    "    if n==len(num_data)-1:\n",
    "        return dic\n",
    "    else:\n",
    "        n+=1\n",
    "        return map_data(data,gr_data,num_data,n,dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I make a dicionary to group data by month per customer_ID\n",
    "def dic_maker(list_link):\n",
    "\n",
    "    data=pd.read_csv(list_link)\n",
    "    \n",
    "    gr_data=data.groupby(\"customer_ID\")[\"S_2\"].count().to_frame().reset_index()\n",
    "\n",
    "    num_data=list(gr_data[\"S_2\"].unique())\n",
    "\n",
    "    max_val=max(num_data)\n",
    "    \n",
    "    num_data.pop(num_data.index(max_val))\n",
    "    \n",
    "    n=0\n",
    "    \n",
    "    dic={}\n",
    "    \n",
    "    dic=map_data(data,gr_data,num_data,n,dic)\n",
    "    \n",
    "    array_ID=gr_data[gr_data[\"S_2\"]==max_val][\"customer_ID\"].unique()\n",
    "    \n",
    "    data=data[data[\"customer_ID\"].isin(array_ID)]\n",
    "    \n",
    "    dic.update({max_val:data})\n",
    "\n",
    "    del data\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_link=['train_num0.csv',\n",
    " 'train_num1.csv',\n",
    " 'train_num2.csv',\n",
    " 'train_num3.csv',\n",
    " 'train_num4.csv',\n",
    " 'train_num5.csv',\n",
    " 'train_num6.csv',\n",
    " 'train_num7.csv',\n",
    " 'train_num8.csv',\n",
    " 'train_num9.csv',\n",
    " 'train_num10.csv',\n",
    " 'train_num11.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cf.ThreadPoolExecutor() as excutor:\n",
    "        data=list(excutor.map(dic_maker,lista_link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a funcion to delet entry in the dicionary as they are being group by month\n",
    "def del_dic(data,num_key,num):\n",
    "\n",
    "    del data[num][num_key]\n",
    "\n",
    "    if num==len(data)-1:\n",
    "        return data\n",
    "    else:\n",
    "        num+=1\n",
    "        return del_dic(data,num_key,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list=list(data[0].keys())\n",
    "arr_key=list(np.arange(1,max(key_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this his how i concatonate all entries by month together with the exeption of the 13 month data\n",
    "def concat_dic(data,arr_key):\n",
    "\n",
    "    num_key=arr_key[0]\n",
    "\n",
    "    data[0][num_key]=pd.concat(list(map(lambda x : x[num_key] , data)))\n",
    "\n",
    "    num=1\n",
    "    \n",
    "    data=del_dic(data,num_key,num)\n",
    "    \n",
    "    arr_key.pop(0)\n",
    "\n",
    "    if len(arr_key)==0:\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        return concat_dic(data,arr_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=concat_dic(data,arr_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5120\n",
      "2\n",
      "6098\n",
      "3\n",
      "5778\n",
      "4\n",
      "4673\n",
      "5\n",
      "4671\n",
      "6\n",
      "5515\n",
      "7\n",
      "5198\n",
      "8\n",
      "6110\n",
      "9\n",
      "6411\n",
      "10\n",
      "6721\n",
      "11\n",
      "5961\n",
      "12\n",
      "10623\n",
      "13\n",
      "34858\n"
     ]
    }
   ],
   "source": [
    "# this is the number of unique customer by month data \n",
    "for x in range(1,len(data[0].keys())+1):\n",
    "    print(x)\n",
    "    print(len(data[0][x][\"customer_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I save the dataframes as csv from the dicionary\n",
    "def read_dic(data,data_keys,n=0):\n",
    "\n",
    "    df=data[data_keys[0]]\n",
    "\n",
    "    if len(data_keys)==1:\n",
    "        n+=1\n",
    "        link=\"train_month\"+str(data_keys[0])+\"_\"+str(n)+\".csv\"\n",
    "\n",
    "    else:\n",
    "        link=\"train_month\"+str(data_keys[0])+\".csv\"\n",
    "    \n",
    "    df.to_csv(link)\n",
    "\n",
    "    data_keys.pop(0)\n",
    "\n",
    "\n",
    "    if len(data_keys)==0:\n",
    "        \n",
    "        del data\n",
    "\n",
    "        return \n",
    "\n",
    "    else:\n",
    "\n",
    "        return read_dic(data,data_keys,n)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(map(lambda x: read_dic(data=x,data_keys=list(x.keys())),data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the 13 month data\n",
    "def save_me(data,n=0):\n",
    "    df=data[n][13]\n",
    "\n",
    "    link=\"train_month13_\"+str(n)+\".csv\"\n",
    "\n",
    "    df.to_csv(link)\n",
    "\n",
    "    if n==len(data)-1:\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        n+=1\n",
    "        return save_me(data,n)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_me(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list=[\"train_month1.csv\",\"train_month2.csv\",\"train_month3.csv\",\n",
    "\"train_month4.csv\",\"train_month5.csv\",\"train_month6.csv\",\n",
    "\"train_month7.csv\",\"train_month8.csv\",\"train_month9.csv\",\n",
    "\"train_month10.csv\",\"train_month11.csv\",\"train_month12.csv\",\n",
    "\"train_month13_0.csv\",\"train_month13_1.csv\",\"train_month13_2.csv\",\n",
    "\"train_month13_3.csv\",\"train_month13_4.csv\",\"train_month13_5.csv\",\n",
    "\"train_month13_6.csv\",\"train_month13_7.csv\",\"train_month13_8.csv\",\n",
    "\"train_month13_10.csv\",\"train_month13_11.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I take out all columns with more then 75 of NAN\n",
    "def change_col(link):\n",
    "    \n",
    "    data_1=pd.read_csv(link)\n",
    "    \n",
    "    data_1=change_type(data_1)\n",
    "    \n",
    "    lista_col=list(filter(lambda x: x if (data_1[x].isnull().sum()/len(data_1[x]))*100>=75 else None,data_1.columns))\n",
    "\n",
    "    data_1.drop(labels=lista_col,axis=1,inplace=True)\n",
    "\n",
    "    data_1.drop(labels=['Unnamed: 0.1', 'Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "    data_1.to_csv(link)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cf.ThreadPoolExecutor() as excutor:\n",
    "    list(excutor.map(change_col,link_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66a65024a80dbc669128121e6b28ee47b9bf545b3d53ac8fdf8b853b16492407"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
